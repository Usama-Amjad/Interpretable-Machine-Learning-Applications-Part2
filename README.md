# Interpretable_Machine_Learning_Applications_Part2
In this project, We developed intepretable machine learning applications explaining individual predictions rather than explaining the behavior of the prediction model as a whole. This had been done via the well known Local Interpretable Model-agnostic Explanations (LIME) as a machine learning interpretation and explanation model.  In particular, in this project, we learned how to go beyond the development and use of machine learning (ML) models, such as regression classifiers, in that we add on explainability and interpretation aspects for individual predictions.
